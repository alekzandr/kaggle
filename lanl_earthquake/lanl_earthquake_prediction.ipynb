{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport os\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom tqdm import tqdm_notebook\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import NuSVR\nfrom sklearn.metrics import mean_absolute_error\npd.options.display.precision = 15\n\nimport lightgbm as lgb\nimport xgboost as xgb\nimport time\nimport datetime\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.linear_model import Ridge, RidgeCV\nimport gc\nfrom catboost import CatBoostRegressor\nimport seaborn as sns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d75a975feef3786e43091e6a358eb858ab6f2bbb"
      },
      "cell_type": "markdown",
      "source": "rows = 150_000\nsegments = int(np.floor(train.shape[0] / rows))\n\n\n    \ntrain[\"sma\"] = train[\"acoustic_data\"].rolling(window = 5).mean()\ntrain[\"sma\"] = train[\"acoustic_data\"].rolling(window = 5).mean()\ntrain[\"ewma\"] = pd.Series.ewm(train['acoustic_data'], span=5).mean()\nx = train['acoustic_data'].values\ntrain['ave'] = x.mean()\ntrain['std'] = x.std()\ntrain['max'] = x.max()\ntrain['min'] = x.min()\n\nX_train = train.drop(labels=\"acoustic_data\", axis=1)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b2a2174da5befb22d21a3abb2b0e5861001e8cc4"
      },
      "cell_type": "code",
      "source": "def preprocess_train(seg_id, train):\n    d = {'sma' : [0],\n         'ewma' : [0],\n         'ave' : [0],\n         'std' : [0],\n         'max' : [0],\n         'min' : [0],\n         'time_to_failure' : [0]}\n    result = pd.DataFrame(d, dtype=np.float64)\n    \n    x = train[\"acoustic_data\"].values\n    result['time_to_failure'] = train[\"time_to_failure\"].values[-1]\n    train[\"sma\"] = train[\"acoustic_data\"].rolling(window = 10).mean()\n    train['ewma'] = pd.Series.ewm(train[\"acoustic_data\"], span=10).mean()\n    result[\"sma\"] = train[\"sma\"].mean()\n    result[\"seg_id\"] = seg_id\n    result[\"ewma\"] = train[\"ewma\"].mean()\n    result['ave'] = 1\n    result['std'] = x.std()\n    result['max'] = x.max()\n    result['min'] = x.min()\n    \n\n    return result",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b24124001fad9a4154617ecf6f22b465a8fc9239"
      },
      "cell_type": "code",
      "source": "frames = []\nrows = 150_000\nsegments = 1\n#train = pd.read_csv('../input/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n\nfor df in pd.read_csv('../input/train.csv', chunksize=rows, dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64}):\n    _ = preprocess_train(segments, df)\n    frames.append(_)\n    segments += 1\n\nX_train = pd.concat(frames)\nX_train = X_train.set_index(\"seg_id\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2b4da04b4d1f6636242bdd1b9efb92811d0d4a90"
      },
      "cell_type": "code",
      "source": "X_train.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "870b77d4512da2a2e58546513ae53fefdc354291"
      },
      "cell_type": "code",
      "source": "X_train.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5e9b2f92a1422ff77cb1ec0b8d2ee03063a91505"
      },
      "cell_type": "code",
      "source": "def modeling_cross_validation(params, X, y, nr_folds=5):\n    clfs = list()\n    oof_preds = np.zeros(X.shape[0])\n    # Split data with kfold\n    kfolds =KFold(n_splits=nr_folds, shuffle=False, random_state=42)\n    for n_fold, (trn_idx, val_idx) in enumerate(kfolds.split(X, y)):\n        X_train, y_train = X.iloc[trn_idx], y.iloc[trn_idx]\n        X_valid, y_valid = X.iloc[val_idx], y.iloc[val_idx]\n\n        print(\"Fold {}\".format(n_fold+1))\n        \n        model = lgb.LGBMRegressor(**params)\n        model.fit(\n            X_train, y_train,\n            eval_set=[(X_valid, y_valid)],\n            verbose=200, eval_metric='mae',\n            early_stopping_rounds=150\n        )\n\n        clfs.append(model)\n        oof_preds[val_idx] = model.predict(X_valid, num_iteration=model.best_iteration_)\n        \n    score = (y, oof_preds)\n    print(score)\n    return clfs, score",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "af61a13f563b76d75cd8488404089ae0955d7e05"
      },
      "cell_type": "code",
      "source": "def predict_cross_validation(test, clfs):\n    sub_preds = np.zeros(test.shape[0])\n    for i, model in enumerate(clfs, 1):    \n        test_preds = model.predict_proba(test, num_iteration=model.best_iteration_)\n        sub_preds += test_preds[:,1]\n\n    sub_preds = sub_preds / len(clfs)\n    ret = pd.Series(sub_preds, index=test.index)\n    ret.index.name = test.index.name\n    return ret\n\n\ndef predict_test_chunk(features, clfs, dtypes, filename='tmp.csv', chunks=100000):\n    \n    for i_c, df in enumerate(pd.read_csv('..test.csv', \n                                         chunksize=chunks, \n                                         dtype=dtypes, \n                                         iterator=True)):\n        \n        df.set_index(TARGET_INDEX, inplace=True)\n\n        preds_df = predict_cross_validation(df[features], clfs)\n        preds_df = preds_df.to_frame(TARGET)\n        \n        print(\"Writing test predictions to file\")\n        \n        if i_c == 0:\n            preds_df.to_csv(filename, header=True, mode='a', index=True)\n        else:\n            preds_df.to_csv(filename, header=False, mode='a', index=True)\n        \n        del preds_df\n        gc.collect()\n        print(\"Grabbin mode tests\")\n    print(\"Done\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6a301a98340015b7dd6a4cc9aa05185b75fd779a"
      },
      "cell_type": "code",
      "source": "params = {'num_leaves': 54,\n         'min_data_in_leaf': 79,\n         'objective': 'regression_l1',\n         'max_depth': 15,\n         'learning_rate': 0.018545526395058548,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.8354507676881442,\n         \"bagging_freq\": 3,\n         \"bagging_fraction\": 0.8126672064208567,\n         \"bagging_seed\": 11,\n         \"metric\": 'mae',\n         \"lambda_l1\": 0.1,\n         \"verbosity\": -1,\n         'min_child_weight': 5.343384366323818,\n         'reg_alpha': 1.1302650970728192,\n         'reg_lambda': 0.3603427518866501,\n         'subsample': 0.8767547959893627,\n         'num_iterations' : 2000}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dac2234c7bac4e9189b90c515dc6b6f327337b7e"
      },
      "cell_type": "code",
      "source": "train_features = list()\n\nTARGET = 'time_to_failure'\n\ntrain_features = [f for f in X_train.columns if f != TARGET]\n    \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "991806eebb74c1de39db92cfb8404120b482d379"
      },
      "cell_type": "markdown",
      "source": "clfs, score = modeling_cross_validation(params, X_train[train_features], X_train[TARGET], nr_folds=5)"
    },
    {
      "metadata": {
        "_uuid": "6ee013b9afc90b59f99130cac04a9c8c54159f45"
      },
      "cell_type": "markdown",
      "source": "Test Code below"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a198ee9a42da1db5d7c816b45f7877fce30c3fa4"
      },
      "cell_type": "code",
      "source": "def sma (x, N):\n    cumsum = np.cumsum(np.insert(x, 0, 0)) \n    temp = (cumsum[N:] - cumsum[:-N]) / float(N)\n    result = np.zeros(len(x) - len(temp))\n    result = np.concatenate((result, temp))\n    #result = np.reshape(result, (len(result),1))\n    return result",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b73db78f2c9ec92f3fbc17d356924a45c9b73441"
      },
      "cell_type": "code",
      "source": "def preprocess(seg_id):\n    d = {'sma' : [0],\n         'ewma' : [0],\n         'ave' : [0],\n         'std' : [0],\n         'max' : [0],\n         'min' : [0]}\n    test = pd.read_csv('../input/test/' + seg_id + '.csv')\n    result = pd.DataFrame(d, dtype=np.float64)\n    \n    x = test[\"acoustic_data\"].values\n    \n    test[\"sma\"] = test[\"acoustic_data\"].rolling(window = 5).mean()\n    test['ewma'] = pd.Series.ewm(test[\"acoustic_data\"], span=5).mean()\n    result[\"sma\"] = test[\"sma\"].mean()\n    result[\"seg_id\"] = seg_id\n    result[\"ewma\"] = test[\"ewma\"].mean()\n    result['ave'] = 1\n    result['std'] = x.std()\n    result['max'] = x.max()\n    result['min'] = x.min()\n    #print(test)\n    #print(result)\n    return result\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "78f54b2de79111c09340044caffb5322d875cc33"
      },
      "cell_type": "code",
      "source": "submission = pd.read_csv('../input/sample_submission.csv', index_col='seg_id')\nindex = pd.DataFrame(columns=X_train.columns, dtype=np.float64, index=submission.index)\nframes = []\nfor seg_id in tqdm_notebook(index.index):\n        _ = preprocess(seg_id)\n        frames.append(_)\nX_test = pd.concat(frames)\nX_test = X_test.set_index(\"seg_id\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c829c47e85d620ca9214af54d9c24a40328f7aa5"
      },
      "cell_type": "code",
      "source": "print(X_test.columns)\nprint(X_train.columns)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "c6bce389273c75fec9fadebe1e5f5286f4206a32"
      },
      "cell_type": "code",
      "source": "print(X_test.head(10))\nprint(X_train.head(10))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8f1e0bf010187672737aed72784b1b4d32ce47c0",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "def train_model(X=X_train[train_features], X_test=X_test, y=X_train[TARGET], params=None, model_type='lgb', plot_feature_importance=False):\n    \n    n_fold = 5\n    folds = KFold(n_splits=n_fold, shuffle=True, random_state=11)\n    oof = np.zeros(len(X))\n    prediction = np.zeros(len(X_test))\n    scores = []\n    feature_importance = pd.DataFrame()\n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n        print('Fold', fold_n, 'started at', time.ctime())\n        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n        \n        if model_type == 'lgb':\n            model = lgb.LGBMRegressor(**params, n_estimators = 20000, nthread = 4, n_jobs = -1)\n            model.fit(X_train, y_train, \n                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='mae',\n                    verbose=1000, early_stopping_rounds=200)\n            \n            y_pred_valid = model.predict(X_valid)\n            #print(X_test.head())\n            #print(train.head())\n            \n            y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n            \n        \n        oof[valid_index] = y_pred_valid.reshape(-1,)\n        scores.append(mean_absolute_error(y_valid, y_pred_valid) ** 0.5)\n        \n        prediction += y_pred    \n        \n        if model_type == 'lgb':\n            # feature importance\n            fold_importance = pd.DataFrame()\n            fold_importance[\"feature\"] = X.columns\n            fold_importance[\"importance\"] = model.feature_importances_\n            fold_importance[\"fold\"] = fold_n + 1\n            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n\n    prediction /= n_fold\n    \n    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n    \n    if model_type == 'lgb':\n        feature_importance[\"importance\"] /= n_fold\n        if plot_feature_importance:\n            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n                by=\"importance\", ascending=False)[:50].index\n\n            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n\n            plt.figure(figsize=(16, 12));\n            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n            plt.title('LGB Features (avg over folds)');\n        \n            return oof, prediction, feature_importance\n        return oof, prediction\n    \n    else:\n        return oof, prediction",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "200de123c4a214c08c6c59f2530d0e7611c24e2b"
      },
      "cell_type": "code",
      "source": "oof_lgb, prediction_lgb, feature_importance = train_model(params=params, model_type='lgb', plot_feature_importance=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0f574276ab66be8f5fd666158a4fda6cf2759755"
      },
      "cell_type": "code",
      "source": "#print(submission.head())\n#print(submission.shape)\nprint(prediction_lgb)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2a48638eb1c7b0a93c69515b1f52d71b761a66c4"
      },
      "cell_type": "code",
      "source": "submission['time_to_failure'] = prediction_lgb\nprint(submission.head())\nsubmission.to_csv('submission.csv')",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}